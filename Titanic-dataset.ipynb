{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98681e25",
   "metadata": {},
   "source": [
    "# Hi! This is my first notebook\n",
    "## And also my first kaggle.. and \"Machine Learning\" project ðŸ˜±ðŸ˜¨ðŸ™€</br>\n",
    "\n",
    "## Let's start ðŸ˜µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d836288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca692de",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1dd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_id = test['PassengerId']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0fe71",
   "metadata": {},
   "source": [
    "### Let's look at some info of the data and it's correlation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4812f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check data first\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df465f6",
   "metadata": {},
   "source": [
    "In both tables, **Age**, **Cabin** are having null values.</br>\n",
    "**Fare** has null only in test data and **Embarked** has null only in train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22203ed2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check correlation\n",
    "corr = train.corr()\n",
    "corr.style.background_gradient(cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cc5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = train.corr(method=\"kendall\")\n",
    "corr.style.background_gradient(cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c35bd7",
   "metadata": {},
   "source": [
    "Next step is **dropping** unused column for the models.</br>I have decided to drop **'PassengerID'**, **'Name'**, **'Ticket and **'Cabin'** columns</br>\n",
    "After that we fill **Age**'s null values with median and **Embarked**'s with 'Unknown'\n",
    "\n",
    "Here i've made reusable code for dropping column and removing null with mean, median, or any string we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80930000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reusable function for column dropping and null value replacing\n",
    "\n",
    "def drop_cols(data, drop_cols): #column-dropping function\n",
    "    data = data.drop(drop_cols, axis=1)\n",
    "    return data\n",
    "\n",
    "def na_median (data, na_cols): #change null to median\n",
    "    for col in na_cols:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "    return data\n",
    "\n",
    "def na_mean (data, na_cols): #change null to mean\n",
    "    for col in na_cols:\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "    return data\n",
    "\n",
    "def na_string (data, na_cols, fillwith): #change null to any string\n",
    "    for col in na_cols:\n",
    "        data[col].fillna('{}'.format(fillwith), inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ba7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use self-built function to clean ðŸ˜€\n",
    "        \n",
    "\n",
    "train = drop_cols(train, ['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "train = na_median(train, ['Age'])\n",
    "train = na_string(train, ['Embarked'], 'U' )\n",
    "\n",
    "test = drop_cols(test, ['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "test = na_median(test, ['Age'])\n",
    "test = na_mean(test, ['Fare'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb7b8a",
   "metadata": {},
   "source": [
    "#### check if it's solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04eb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a52a5",
   "metadata": {},
   "source": [
    "ðŸ™„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085edda",
   "metadata": {},
   "source": [
    "### Change 'Sex' and 'Embarked' columns to numerical value\n",
    "#### as Sex and Embarked columns datatype is object, we should change them so that it'll fit to the \"machine learning model\" ðŸ¤ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d5f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "columns = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "for col in columns:\n",
    "    \n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    print(le.classes_)\n",
    "    \n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df640ce",
   "metadata": {},
   "source": [
    "**'Sex'** and **'Embarked'** has changed to int datatype from objects<br/><br/>\n",
    "New numbers of them are assigned to 0-started index alphabetically (0 is **F**emale, 1 is **M**ale;\n",
    "0 is **C**, 1 is 2 is **Q** and so on)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc3bb87",
   "metadata": {},
   "source": [
    "Now, lets split our training datasets for the model building. Also before that,<br/>we must define first our \"**x-and-y**\" (independent and dependent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train['Survived'] # assign survive column as models decide it\n",
    "x = train.drop(\"Survived\", axis=1) # assign the rest as the predictors\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd78c1f",
   "metadata": {},
   "source": [
    "Then, import classifiers from **sklearn**ðŸ¤” to build then train our modelsðŸ’ƒ of \"Machine Learning\" ðŸ˜±ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier # you may need to install this classifier first\n",
    "# run in the code cell \"pip install xgboost\" and restart the kernel, voila!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec387f29",
   "metadata": {},
   "source": [
    "Then import those below to score our classifiers. Accuracy is accuracy ðŸ˜¬ and cross_val_score is cross validation score ðŸ˜¬ðŸ˜¬ðŸ˜¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21483f7",
   "metadata": {},
   "source": [
    "Well, accuracy measure how accurate your model predict the y-value\n",
    "for example</br>\n",
    "y_predict = [0,1,1,0]</br>\n",
    "y_actual  = [0,0,1,1]</br>\n",
    "Then your model's accuracy is 0.5. (first and third of them are matches)\n",
    "\n",
    "For cross validation.... Google may explain better for you I guess ðŸ˜¬ðŸ˜¬ðŸ˜¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8244c",
   "metadata": {},
   "source": [
    "After that, the show goes on ðŸ¥³\n",
    "\n",
    "Train our model and let's see which model produce best cross validation score ðŸ‘€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16993716",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef229de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(random_state=0, max_iter=100).fit(x_train, y_train)\n",
    "cv_lr = cross_val_score(LogisticRegression(), x_train, y_train, cv=5)\n",
    "y_val_pred = clf_lr.predict(x_val)\n",
    "acc_lr = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(cv_lr)\n",
    "print(cv_lr.mean())\n",
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeefae7",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = tree.DecisionTreeClassifier(random_state=42).fit(x_train, y_train)\n",
    "cv_tree = cross_val_score(tree.DecisionTreeClassifier(), x_train, y_train, cv=5)\n",
    "y_val_tree = clf_tree.predict(x_val)\n",
    "acc_tree = accuracy_score(y_val, y_val_tree)\n",
    "\n",
    "\n",
    "print(cv_tree)\n",
    "print(cv_tree.mean())\n",
    "print(acc_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc9b4d",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier().fit(x_train, y_train)\n",
    "cv_knn = cross_val_score(KNeighborsClassifier(), x_train, y_train, cv=5)\n",
    "y_val_knn = clf_knn.predict(x_val)\n",
    "acc_knn = accuracy_score(y_val, y_val_knn)\n",
    "\n",
    "print(cv_knn)\n",
    "print(cv_knn.mean())\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a48b3",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rdf = RandomForestClassifier(random_state = 1).fit(x_train, y_train)\n",
    "cv_rdf = cross_val_score(RandomForestClassifier(random_state = 1), x_train, y_train, cv=5)\n",
    "y_val_rdf = clf_rdf.predict(x_val)\n",
    "acc_rdf = accuracy_score(y_val, y_val_rdf)\n",
    "\n",
    "print(cv_rdf)\n",
    "print(cv_rdf.mean())\n",
    "print(acc_rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424b614",
   "metadata": {},
   "source": [
    "#### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9caeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier(random_state =1).fit(x_train, y_train)\n",
    "cv_xgb = cross_val_score(XGBClassifier(random_state =1), x_train, y_train, cv=5)\n",
    "y_val_xgb = clf_xgb.predict(x_val)\n",
    "acc_xgb = accuracy_score(y_val, y_val_xgb)\n",
    "\n",
    "print(cv_xgb)\n",
    "print(cv_xgb.mean())\n",
    "print(acc_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e84096",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC().fit(x_train, y_train)\n",
    "cv_svc = cross_val_score(SVC(), x_train, y_train, cv=5)\n",
    "y_val_svc = clf_svc.predict(x_val)\n",
    "acc_svc = accuracy_score(y_val, y_val_svc)\n",
    "\n",
    "print(cv_svc)\n",
    "print(cv_svc.mean())\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f3a69",
   "metadata": {},
   "source": [
    "### Suddenly i feel like I want to apply my bitesize knowledge about 'Classes and Object' soo...\n",
    "#### First, I made it to store every result I made\n",
    "#### Then I realize that all of process in the cell above can be made here. So it's possible that all down below do not a \"storage\" anymore. Instead, it act as the \"factory\" ðŸ˜“\n",
    "As you can see, the *cvsscore* and *accuracy* function inside class is not parsed, but it's calculating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597085f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MLclfs:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set(self, cvstype, clfstype, accuracy, modelname, newclfs):\n",
    "        self.cvs = cvstype\n",
    "        self.clfs = clfstype\n",
    "        self.acc = accuracy\n",
    "        self.name = modelname\n",
    "        self.clfs_new = newclfs\n",
    "        \n",
    "    def cvsmean(self):\n",
    "        return self.cvs.mean()\n",
    "        \n",
    "    def cvsscore(self):\n",
    "        return cross_val_score(self.clfs_new, x_train, y_train, cv=5)\n",
    "    \n",
    "    def y_result(self, testdata):\n",
    "        return self.clfs_new.fit(x_train, y_train).predict(testdata)\n",
    "    \n",
    "    def accuracy(self):\n",
    "        return accuracy_score(y_val, self.clfs_new.fit(x_train, y_train).predict(x_val))\n",
    "\n",
    "lr, dtree, knn, rdf, xgb, suppvc = [MLclfs() for i in range(6)]\n",
    "\n",
    "name = [lr,dtree,knn,rdf,xgb,suppvc]\n",
    "cvs = [cv_lr, cv_tree, cv_knn, cv_rdf, cv_xgb, cv_svc]\n",
    "clfs = [clf_lr, clf_tree, clf_knn, clf_rdf, clf_xgb,clf_svc]\n",
    "acc = [acc_lr, acc_tree, acc_knn, acc_rdf, acc_xgb, acc_svc]\n",
    "modelname = [\"Logistic Regression\", \"Decision Tree\", \"K-Nearest Neighbor\",\n",
    "             \"Random Forest\", \"Extreme Gradient Boost\", \"SVC\"]\n",
    "clfs_new = [LogisticRegression(random_state = 1, max_iter = 1000), tree.DecisionTreeClassifier(), KNeighborsClassifier(),\n",
    "            RandomForestClassifier(random_state = 1), XGBClassifier(random_state =1), SVC()]\n",
    "\n",
    "for i in range(len(name)):\n",
    "    name[i].set(cvs[i], clfs[i], acc[i], modelname[i], clfs_new[i])\n",
    "\n",
    "mean_array = []   \n",
    "def get_all_mean():\n",
    "    print(\"\\nMean :\")\n",
    "    for i in range(len(name)):\n",
    "        mean_result = print(\"{} = \".format(modelname[i]), name[i].cvsmean())\n",
    "        mean_array.append(name[i].cvsmean())\n",
    "    return mean_result, mean_array\n",
    "\n",
    "\n",
    "def get_all_score():\n",
    "    print(\"\\nScore of 5 Cross Validation :\")\n",
    "    for i in range(len(name)):\n",
    "        score_result = print(\"{} = \".format(modelname[i]), name[i].cvsscore())\n",
    "    return score_result\n",
    "\n",
    "def get_all_accuracy():\n",
    "    print(\"\\nAccuracy :\")\n",
    "    for i in range(len(name)):\n",
    "        acc_result = print(\"{} = \".format(modelname[i]), name[i].accuracy())\n",
    "    return acc_result\n",
    "\n",
    "def max_mean():\n",
    "    return print(\"\\nMax mean = \", max(mean_array))\n",
    "\n",
    "# lr.cvsmean\n",
    "# get_all_mean()\n",
    "# get_all_accuracy()\n",
    "# get_all_score()\n",
    "# max_mean()\n",
    "# dtree.y_result(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f42ca",
   "metadata": {},
   "source": [
    "### Should we try on normalized/standardized \"Fare\" and \"Age\" ?.....\n",
    "#### *should've create the training of models as a function before ðŸ˜ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836d098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.plot(kind='box', figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944745c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#train['NormalizedFare'] = (train.Fare - train.Fare.min()) / (train.Fare.max()- train.Fare.min())\n",
    "#train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a68fb5",
   "metadata": {},
   "source": [
    "### OK but maybe just later for the next \"version\" ðŸŒˆ\n",
    "Later some improvement can be applied such as **train with normalized/standardized Fare and Age.**</br>\n",
    "Or **adding another independent variables** such as **title of the passenger** (with some regexðŸ¥´),</br>\n",
    "or something we can determine from the **Ticket** and **Cabin** maybe...\n",
    "\n",
    "Just like Mark Twain says, it really got me like ðŸ™‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496845a1",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"https://user-images.githubusercontent.com/111634631/188610723-dfb26c25-1e9c-42d0-a672-027b700b67ce.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f62c5f",
   "metadata": {},
   "source": [
    "So, until next time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba669c5",
   "metadata": {},
   "source": [
    "I wanna try submitting to Kaggle with **Random Forest** for the classifier, let's see how bad the mark I'll getðŸ˜¬ðŸ˜©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = rdf.y_result(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4525770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'PassengerId': test_id.values,\n",
    "                 'Survived': test_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c52854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Kagglesubmission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
